"""
GitHub Codespaces è¨“ç·´è…³æœ¬
ä½¿ç”¨ TensorFlow 2.16 + tf-keras (Keras 2 ç›¸å®¹) è¼¸å‡º TFJS æ ¼å¼

å®‰è£ä¾è³´:
    pip install tensorflow==2.16.2 tf-keras tensorflowjs pillow

åŸ·è¡Œ:
    python train_codespace.py
"""

import os
os.environ['TF_USE_LEGACY_KERAS'] = '1'  # ä½¿ç”¨ Keras 2 API
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import json
import tf_keras as keras
from tf_keras.applications import MobileNetV2
from tf_keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tf_keras.models import Model
from tf_keras.preprocessing.image import ImageDataGenerator

print(f"Keras version: {keras.__version__}")

# è¨­å®š
TRAIN_DIR = "train"
MODEL_DIR = "docs/model"
CATEGORIES = ["garbage", "metal_can", "paper", "paper_container", "plastic"]

def main():
    print("\n" + "="*50)
    print("ğŸ—‘ï¸ SmartRecycle - Codespaces è¨“ç·´")
    print("="*50)
    
    # æª¢æŸ¥è³‡æ–™
    print("\nğŸ“Š æª¢æŸ¥è¨“ç·´è³‡æ–™...")
    for cat in CATEGORIES:
        path = os.path.join(TRAIN_DIR, cat)
        if os.path.exists(path):
            count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
            print(f"  {cat}: {count} å¼µ")
    
    # è³‡æ–™å¢å¼·
    datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        validation_split=0.2
    )
    
    train_gen = datagen.flow_from_directory(
        TRAIN_DIR, target_size=(224, 224), batch_size=16,
        class_mode='categorical', classes=CATEGORIES, subset='training'
    )
    
    val_gen = datagen.flow_from_directory(
        TRAIN_DIR, target_size=(224, 224), batch_size=16,
        class_mode='categorical', classes=CATEGORIES, subset='validation'
    )
    
    print(f"\n  è¨“ç·´: {train_gen.samples}, é©—è­‰: {val_gen.samples}")
    
    # å»ºç«‹æ¨¡å‹
    print("\nğŸ—ï¸ å»ºç«‹æ¨¡å‹...")
    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    base.trainable = False
    
    x = GlobalAveragePooling2D()(base.output)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.3)(x)
    outputs = Dense(len(CATEGORIES), activation='softmax')(x)
    
    model = Model(inputs=base.input, outputs=outputs)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    
    # è¨“ç·´
    print("\nğŸš€ é–‹å§‹è¨“ç·´...")
    history = model.fit(train_gen, epochs=10, validation_data=val_gen, verbose=1)
    
    print(f"\nğŸ“ˆ æœ€çµ‚é©—è­‰æº–ç¢ºç‡: {history.history['val_accuracy'][-1]:.2%}")
    
    # å…ˆå„²å­˜ H5 æ ¼å¼
    print("\nğŸ“¦ å„²å­˜æ¨¡å‹...")
    os.makedirs(MODEL_DIR, exist_ok=True)
    h5_path = os.path.join(MODEL_DIR, "model.h5")
    model.save(h5_path)
    print(f"  âœ… H5 æ¨¡å‹å·²å„²å­˜: {h5_path}")
    
    # åŒ¯å‡º TFJS (ä½¿ç”¨å‘½ä»¤è¡Œ)
    print("\nğŸ“¦ è½‰æ›ç‚º TensorFlow.js...")
    import subprocess
    result = subprocess.run([
        'tensorflowjs_converter',
        '--input_format=keras',
        h5_path,
        MODEL_DIR
    ], capture_output=True, text=True)
    
    if result.returncode != 0:
        print(f"  âš ï¸ è½‰æ›è¼¸å‡º: {result.stderr}")
    
    # ä¿®å¾© model.json ç›¸å®¹æ€§
    print("\nğŸ”§ ä¿®å¾© model.json ç›¸å®¹æ€§...")
    model_json_path = os.path.join(MODEL_DIR, "model.json")
    if os.path.exists(model_json_path):
        with open(model_json_path, 'r') as f:
            data = json.load(f)
        
        # ä¿®å¾© InputLayer
        def fix_layer(layer):
            cfg = layer.get('config', {})
            if layer.get('class_name') == 'InputLayer':
                if 'batch_shape' in cfg:
                    cfg['batchInputShape'] = cfg.pop('batch_shape')
            if 'dtype' in cfg and isinstance(cfg['dtype'], dict):
                cfg['dtype'] = cfg['dtype'].get('config', {}).get('name', 'float32')
            for key in ['kernel_initializer', 'bias_initializer', 'depthwise_initializer']:
                if key in cfg and isinstance(cfg[key], dict):
                    for rm in ['module', 'registered_name']:
                        cfg[key].pop(rm, None)
        
        def fix_nodes(nodes):
            fixed = []
            for node in nodes:
                if isinstance(node, dict) and 'args' in node:
                    args = node.get('args', [])
                    if args and isinstance(args[0], dict):
                        h = args[0].get('config', {}).get('keras_history', [])
                        if h:
                            fixed.append([[h[0], h[1], h[2], {}]])
                        else:
                            fixed.append([])
                    elif args and isinstance(args[0], list):
                        inputs = []
                        for item in args[0]:
                            if isinstance(item, dict):
                                h = item.get('config', {}).get('keras_history', [])
                                if h:
                                    inputs.append([h[0], h[1], h[2], {}])
                        fixed.append(inputs if inputs else [])
                    else:
                        fixed.append([])
                else:
                    fixed.append(node if isinstance(node, list) else [])
            return fixed
        
        topology = data.get('modelTopology', {}).get('model_config', {}).get('config', {})
        for layer in topology.get('layers', []):
            fix_layer(layer)
            if 'inbound_nodes' in layer:
                layer['inbound_nodes'] = fix_nodes(layer['inbound_nodes'])
        
        with open(model_json_path, 'w') as f:
            json.dump(data, f, separators=(',', ':'))
        print("  âœ… model.json å·²ä¿®å¾©")
    
    # å„²å­˜æ¨™ç±¤
    with open(os.path.join(MODEL_DIR, "labels.json"), 'w') as f:
        json.dump(CATEGORIES, f, indent=2)
    
    # æ¸…ç† H5
    os.remove(h5_path)
    
    print(f"\nâœ… æ¨¡å‹å·²åŒ¯å‡ºè‡³ {MODEL_DIR}/")
    print("\nä¸‹ä¸€æ­¥: git add, commit, push åˆ° GitHub Pages")

if __name__ == "__main__":
    main()
